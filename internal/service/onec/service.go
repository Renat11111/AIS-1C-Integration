package onec

import (
	"bytes"
	"context"
	"encoding/json"
	"fmt"
	"io"
	"net/http"
	"strings"
	"sync"
	"time"

	"ais-1c-proxy/internal/config"
	"ais-1c-proxy/internal/metrics"
	"ais-1c-proxy/internal/models"

	"github.com/pocketbase/dbx"
	"github.com/pocketbase/pocketbase"
	"github.com/pocketbase/pocketbase/core"
	"github.com/prometheus/client_golang/prometheus"
	"github.com/rs/zerolog/log"
)

const (
	CollectionQueue   = "integration_queue"
	WorkerCount       = 5
	BatchSize         = 50
	ChannelBuffer     = 100
	MaxRetries        = 10              // –ú–∞–∫—Å–∏–º—É–º –ø–æ–ø—ã—Ç–æ–∫ –ø–µ—Ä–µ–¥ –ø–µ—Ä–µ–º–µ—â–µ–Ω–∏–µ–º –≤ DLQ (failed)
	BaseRetryInterval = 1 * time.Minute // –ù–∞—á–∞–ª—å–Ω—ã–π –∏–Ω—Ç–µ—Ä–≤–∞–ª –ø–æ–≤—Ç–æ—Ä–∞

	// Circuit Breaker Config
	CBFailureThreshold = 5                // –°–∫–æ–ª—å–∫–æ –æ—à–∏–±–æ–∫ –ø–æ–¥—Ä—è–¥ –¥–æ —Ä–∞–∑–º—ã–∫–∞–Ω–∏—è
	CBOpenDuration     = 30 * time.Second // –°–∫–æ–ª—å–∫–æ –∂–¥–∞—Ç—å –ø–µ—Ä–µ–¥ –ø–æ–ø—ã—Ç–∫–æ–π –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è
)

type CBState int

const (
	StateClosed CBState = iota
	StateOpen
	StateHalfOpen
)

type Service struct {
	app     *pocketbase.PocketBase
	cfg     *config.Config
	client  *http.Client
	bufPool sync.Pool
	jobs    chan []*core.Record // –¢–µ–ø–µ—Ä—å –ø–µ—Ä–µ–¥–∞–µ–º –ø–∞—á–∫–∏ –∑–∞–ø–∏—Å–µ–π
	notify  chan struct{}       // –ö–∞–Ω–∞–ª –¥–ª—è –ø—Ä–æ–±—É–∂–¥–µ–Ω–∏—è –¥–∏—Å–ø–µ—Ç—á–µ—Ä–∞
	wg      sync.WaitGroup

	// Circuit Breaker State
	cbState     CBState
	cbFailures  int
	cbLastRetry time.Time
	cbMu        sync.RWMutex
}

func NewService(app *pocketbase.PocketBase, cfg *config.Config) *Service {
	return &Service{
		app:    app,
		cfg:    cfg,
		client: &http.Client{Timeout: cfg.OneCTimeout},
		bufPool: sync.Pool{
			New: func() interface{} {
				return bytes.NewBuffer(make([]byte, 0, 4096)) // 4KB –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–ª—è –æ–¥–Ω–æ–≥–æ –∏–Ω–≤–æ–π—Å–∞
			},
		},
		jobs:    make(chan []*core.Record, ChannelBuffer),
		notify:  make(chan struct{}, 1),
		cbState: StateClosed,
	}
}

func (s *Service) getCBState() CBState {
	// ... (–æ—Å—Ç–∞–≤–ª—è–µ–º –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π)
	s.cbMu.RLock()
	defer s.cbMu.RUnlock()

	if s.cbState == StateOpen {
		if time.Since(s.cbLastRetry) > CBOpenDuration {
			return StateHalfOpen
		}
	}
	return s.cbState
}

func (s *Service) recordCBSuccess() {
	s.cbMu.Lock()
	defer s.cbMu.Unlock()
	s.cbState = StateClosed
	s.cbFailures = 0
	log.Info().Msg("üõ°Ô∏è Circuit Breaker: CLOSED (System restored)")
}

func (s *Service) recordCBFailure() {
	s.cbMu.Lock()
	defer s.cbMu.Unlock()
	s.cbFailures++
	if s.cbFailures >= CBFailureThreshold && s.cbState != StateOpen {
		s.cbState = StateOpen
		s.cbLastRetry = time.Now()
		log.Warn().Int("failures", s.cbFailures).Msg("üõ°Ô∏è Circuit Breaker: OPEN (1C is down, pausing requests)")
	}
}

func (s *Service) EnsureQueueCollection() error {
	// ... (–æ—Å—Ç–∞–≤–ª—è–µ–º –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π)
	col, err := s.app.FindCollectionByNameOrId(CollectionQueue)
	if err != nil {
		log.Info().Msg("Bootstrap: Creating 'integration_queue' collection...")
		col = core.NewBaseCollection(CollectionQueue)
		col.Type = core.CollectionTypeBase
	} else {
		log.Debug().Msg("Bootstrap: Checking 'integration_queue' fields...")
	}

	// –°–ø–∏—Å–æ–∫ –ø–æ–ª–µ–π, –∫–æ—Ç–æ—Ä—ã–µ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –≤ –∫–æ–ª–ª–µ–∫—Ü–∏–∏
	requiredFields := []core.Field{
		&core.TextField{Name: "ais_id", Required: true},
		&core.TextField{Name: "method", Required: true},
		&core.JSONField{Name: "payload", Required: true},
		&core.SelectField{Name: "status", MaxSelect: 1, Values: []string{"pending", "processing", "retry", "failed", "error"}},
		&core.TextField{Name: "error_log"},
		&core.NumberField{Name: "retry_count"},
		&core.DateField{Name: "next_attempt"},
		&core.DateField{Name: "created"},
		&core.DateField{Name: "updated"},
	}

	modified := false
	for _, rf := range requiredFields {
		if col.Fields.GetByName(rf.GetName()) == nil {
			log.Info().Str("field", rf.GetName()).Msg("Adding missing field to collection")
			col.Fields.Add(rf)
			modified = true
		}
	}

	// –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–æ–≤
	indexes := []struct {
		name   string
		unique bool
		cols   string
	}{
		{"idx_status", false, "status"},
		{"idx_ais_id", true, "ais_id"},
		{"idx_next_attempt", false, "next_attempt"},
	}

	for _, idx := range indexes {
		exists := false
		for _, existingIdx := range col.Indexes {
			// –í PocketBase v0.35 –∏–Ω–¥–µ–∫—Å—ã - —ç—Ç–æ –º–∞—Å—Å–∏–≤ —Å—Ç—Ä–æ–∫ (CREATE INDEX...)
			// –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å–æ–¥–µ—Ä–∂–∏—Ç—Å—è –ª–∏ –∏–º—è –Ω–∞—à–µ–≥–æ –∏–Ω–¥–µ–∫—Å–∞ –≤ —ç—Ç–æ–π —Å—Ç—Ä–æ–∫–µ
			if strings.Contains(existingIdx, idx.name) {
				exists = true
				break
			}
		}
		if !exists {
			log.Info().Str("index", idx.name).Msg("Adding missing index to collection")
			col.AddIndex(idx.name, idx.unique, idx.cols, "")
			modified = true
		}
	}

	if modified || col.Id == "" {
		if err := s.app.Save(col); err != nil {
			return err
		}
	}

	return s.RecoverStuckRecords()
}

// RecoverStuckRecords –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∑–∞–ø–∏—Å–∏ –∏–∑ 'processing' –≤ 'pending' –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ
func (s *Service) RecoverStuckRecords() error {
	records, err := s.app.FindRecordsByFilter(
		CollectionQueue,
		"status = 'processing'",
		"created",
		0,
		0,
		nil,
	)
	if err != nil {
		return err
	}

	if len(records) == 0 {
		return nil
	}

	log.Info().Int("count", len(records)).Msg("üõ†Ô∏è Recovery: Resetting stuck 'processing' records to 'pending'")
	for _, r := range records {
		r.Set("status", "pending")
		if err := s.app.Save(r); err != nil {
			log.Error().Err(err).Str("id", r.Id).Msg("Failed to recover record")
		}
	}
	return nil
}

func (s *Service) Push(req models.AISRequest) error {
	collection, err := s.app.FindCollectionByNameOrId(CollectionQueue)
	if err != nil {
		return err
	}
	existing, _ := s.app.FindFirstRecordByFilter(CollectionQueue, "ais_id = {:id}", map[string]interface{}{"id": req.ID})
	if existing != nil {
		log.Warn().Str("id", req.ID).Msg("Duplicate request ID ignored")
		return nil
	}
	record := core.NewRecord(collection)
	record.Set("ais_id", req.ID)
	record.Set("method", req.Method)
	record.Set("payload", req.Data)
	record.Set("status", "pending")

	if err := s.app.Save(record); err != nil {
		return err
	}

	// –£–≤–µ–¥–æ–º–ª—è–µ–º –¥–∏—Å–ø–µ—Ç—á–µ—Ä –æ –Ω–æ–≤–æ–π –∑–∞–ø–∏—Å–∏
	select {
	case s.notify <- struct{}{}:
	default:
		// –ö–∞–Ω–∞–ª –ø–æ–ª–æ–Ω, –¥–∏—Å–ø–µ—Ç—á–µ—Ä –∏ —Ç–∞–∫ –ø—Ä–æ—Å–Ω–µ—Ç—Å—è
	}

	return nil
}

func (s *Service) StartBackgroundWorker(ctx context.Context) {
	for i := 0; i < s.cfg.WorkerCount; i++ {
		s.wg.Add(1)
		go s.worker(ctx, i)
	}
	log.Info().Int("count", s.cfg.WorkerCount).Msg("Started 1C integration workers")

	s.wg.Add(1)
	go s.dispatcher(ctx)
}

// Wait blocks until all background workers are stopped
func (s *Service) Wait() {
	s.wg.Wait()
	log.Info().Msg("All workers stopped gracefully")
}

func (s *Service) dispatcher(ctx context.Context) {
	defer s.wg.Done()
	log.Info().Msg("Started DB Dispatcher (Pure Event-driven)")

	for {
		// 1. –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ç–æ, —á—Ç–æ –≥–æ—Ç–æ–≤–æ –ø—Ä—è–º–æ —Å–µ–π—á–∞—Å
		processed := s.fetchAndDispatch()

		// 2. –ï—Å–ª–∏ –æ–±—Ä–∞–±–æ—Ç–∞–ª–∏ –ø–æ–ª–Ω—É—é –ø–∞—á–∫—É, –≤–æ–∑–º–æ–∂–Ω–æ –µ—Å—Ç—å –µ—â–µ - –∏–¥–µ–º –Ω–∞ –Ω–æ–≤—ã–π –∫—Ä—É–≥ –Ω–µ–º–µ–¥–ª–µ–Ω–Ω–æ
		if processed >= s.cfg.BatchSize {
			continue
		}

		// 3. –í—ã—è—Å–Ω—è–µ–º, –∫–æ–≥–¥–∞ –ø—Ä–æ—Å–Ω—É—Ç—å—Å—è –≤ —Å–ª–µ–¥—É—é—â–∏–π —Ä–∞–∑
		// –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é —Å–ø–∏–º 1 –º–∏–Ω—É—Ç—É (–∫–∞–∫ watchdog), –µ—Å–ª–∏ –∑–∞–¥–∞—á –Ω–µ—Ç
		waitDuration := 1 * time.Minute

		// –ò—â–µ–º –≤—Ä–µ–º—è –±–ª–∏–∂–∞–π—à–µ–≥–æ –ø–æ–≤—Ç–æ—Ä–∞
		var nextAttemptStr string
		err := s.app.DB().Select("MIN(next_attempt)").
			From(CollectionQueue).
			Where(dbx.NewExp("status = 'retry'")).
			Row(&nextAttemptStr)

		if err == nil && nextAttemptStr != "" {
			// PocketBase –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –≤—Ä–µ–º—è –≤ —Ñ–æ—Ä–º–∞—Ç–µ UTC
			nextTime, parseErr := time.Parse("2006-01-02 15:04:05.000Z", nextAttemptStr)
			if parseErr == nil {
				waitDuration = time.Until(nextTime)
				if waitDuration < 0 {
					waitDuration = 0 // –£–∂–µ –ø–æ—Ä–∞ –±—ã–ª–æ –∑–∞–ø—É—Å—Ç–∏—Ç—å
				}
				// –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –æ–∂–∏–¥–∞–Ω–∏–µ 1 –º–∏–Ω—É—Ç–æ–π –Ω–∞ —Å–ª—É—á–∞–π –ø—Ä–∞–≤–æ–∫ –≤ Admin UI
				if waitDuration > 1*time.Minute {
					waitDuration = 1 * time.Minute
				}
			}
		}

		timer := time.NewTimer(waitDuration)

		select {
		case <-ctx.Done():
			timer.Stop()
			log.Info().Msg("Dispatcher stopping...")
			return
		case <-s.notify:
			timer.Stop()
			// –ü—Ä–æ—Å–Ω—É–ª–∏—Å—å –ø–æ —Å–∏–≥–Ω–∞–ª—É –æ –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
		case <-timer.C:
			// –ù–∞—Å—Ç—É–ø–∏–ª–æ –≤—Ä–µ–º—è –∑–∞–ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –ø–æ–≤—Ç–æ—Ä–∞
		}
	}
}
func (s *Service) fetchAndDispatch() int {
	// –°—á–∏—Ç–∞–µ–º –≥–ª—É–±–∏–Ω—É –æ—á–µ—Ä–µ–¥–∏ (–æ–∂–∏–¥–∞—é—â–∏–µ + –ø–æ–≤—Ç–æ—Ä—ã)
	totalPending, _ := s.app.CountRecords(CollectionQueue, dbx.NewExp("status = 'pending' OR status = 'retry'"))
	metrics.QueueDepth.Set(float64(totalPending))

	// –í—ã—á–∏—Å–ª—è–µ–º –≤—Ä–µ–º—è 10 –º–∏–Ω—É—Ç –Ω–∞–∑–∞–¥ –¥–ª—è –ø–æ–∏—Å–∫–∞ –∑–∞–≤–∏—Å—à–∏—Ö –≤ 'processing'
	stuckTime := time.Now().Add(-10 * time.Minute).Format("2006-01-02 15:04:05.000Z")

	// –§–∏–ª—å—Ç—Ä: –Ω–æ–≤—ã–µ, –ø–æ–≤—Ç–æ—Ä—ã –ø–æ –≤—Ä–µ–º–µ–Ω–∏, –∏–ª–∏ –∑–∞–≤–∏—Å—à–∏–µ –≤ processing –±–æ–ª–µ–µ 10 –º–∏–Ω—É—Ç
	filter := fmt.Sprintf("status = 'pending' || (status = 'retry' && next_attempt <= @now) || (status = 'processing' && updated <= '%s')", stuckTime)

	records, err := s.app.FindRecordsByFilter(
		CollectionQueue,
		filter,
		"created",
		s.cfg.BatchSize,
		0,
		nil,
	)
	if err != nil {
		log.Error().Err(err).Msg("Dispatcher failed to fetch records")
		return 0
	}

	count := len(records)
	if count == 0 {
		return 0
	}

	log.Debug().Int("count", count).Msg("Dispatcher found tasks")

	// –ë–ª–æ–∫–∏—Ä—É–µ–º –≤—Å—é –ø–∞—á–∫—É —Å—Ä–∞–∑—É
	for _, record := range records {
		record.Set("status", "processing")
		if err := s.app.Save(record); err != nil {
			log.Error().Err(err).Str("id", record.Id).Msg("Failed to lock record")
			continue
		}
	}

	// –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤—Å—é –ø–∞—á–∫—É –≤ –∫–∞–Ω–∞–ª –∫–∞–∫ –û–î–ù–£ –∑–∞–¥–∞—á—É –¥–ª—è –≤–æ—Ä–∫–µ—Ä–∞
	s.jobs <- records

	return count
}

func (s *Service) worker(ctx context.Context, id int) {
	defer s.wg.Done()
	for {
		select {
		case <-ctx.Done():
			log.Debug().Int("worker_id", id).Msg("Worker stopping...")
			return
		case records := <-s.jobs:
			s.processBatch(ctx, id, records)
		}
	}
}

func (s *Service) processBatch(ctx context.Context, workerID int, records []*core.Record) {
	if len(records) == 0 {
		return
	}

	timer := prometheus.NewTimer(metrics.WorkerDuration)
	defer timer.ObserveDuration()

	// 1. –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ Circuit Breaker
	state := s.getCBState()
	if state == StateOpen {
		log.Debug().Int("batch_size", len(records)).Msg("üõ°Ô∏è Circuit Breaker is OPEN. Skipping batch.")
		for _, r := range records {
			s.handleError(r, fmt.Errorf("circuit breaker is open"), false)
		}
		return
	}

	// 2. –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ (–∏—Å–ø–æ–ª—å–∑—É–µ–º –ø—É–ª –±—É—Ñ–µ—Ä–æ–≤)
	buf := s.bufPool.Get().(*bytes.Buffer)
	buf.Reset()
	defer s.bufPool.Put(buf)

	batchRequests := make([]models.AISRequest, 0, len(records))
	for _, record := range records {
		var payloadData models.AISDocument

		// –û—á–∏—â–∞–µ–º –±—É—Ñ–µ—Ä –¥–ª—è –∫–∞–∂–¥–æ–π –∑–∞–ø–∏—Å–∏ –≤ –±–∞—Ç—á–µ
		buf.Reset()

		// –ö–æ–¥–∏—Ä—É–µ–º payload –∏–∑ –∑–∞–ø–∏—Å–∏ –≤ –±—É—Ñ–µ—Ä
		if err := json.NewEncoder(buf).Encode(record.Get("payload")); err != nil {
			log.Error().Err(err).Str("record_id", record.Id).Msg("Failed to encode payload in batch")
			s.handleError(record, err, true)
			continue
		}

		// –î–µ–∫–æ–¥–∏—Ä—É–µ–º –∏–∑ –±—É—Ñ–µ—Ä–∞ –≤ —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º UseNumber
		decoder := json.NewDecoder(buf)
		decoder.UseNumber()
		if err := decoder.Decode(&payloadData); err != nil {
			log.Error().Err(err).Str("record_id", record.Id).Msg("Failed to decode payload in batch")
			s.handleError(record, err, true)
			continue
		}

		batchRequests = append(batchRequests, models.AISRequest{
			ID:     record.GetString("ais_id"),
			Method: record.GetString("method"),
			Data:   payloadData,
		})
	}

	if len(batchRequests) == 0 {
		return
	}

	// –î–ª—è –ª–æ–≥–æ–≤ –±–µ—Ä–µ–º SaleId –ø–µ—Ä–≤–æ–π –∑–∞–ø–∏—Å–∏ (—Ç–µ–ø–µ—Ä—å —ç—Ç–æ json.Number –∏–ª–∏ string)
	firstSaleId := batchRequests[0].Data.SaleId
	log.Info().
		Int("worker", workerID).
		Int("batch_size", len(batchRequests)).
		Any("first_sale_id_val", firstSaleId).
		Str("first_sale_id_type", fmt.Sprintf("%T", firstSaleId)).
		Msg("üöÄ Processing batch")

	// 3. –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –ü–ê–ö–ï–¢ –≤ 1–°
	err := s.sendBatchToOneC(ctx, batchRequests)

	if err != nil {
		log.Error().Err(err).Int("batch_size", len(batchRequests)).Msg("‚ùå Batch sync failed")
		s.recordCBFailure()
		for _, r := range records {
			s.handleError(r, err, false)
			metrics.ProcessedTotal.WithLabelValues("error", "batch").Inc()
		}
	} else {
		log.Info().Int("batch_size", len(batchRequests)).Msg("‚úÖ Batch sync success")
		s.recordCBSuccess()
		for _, r := range records {
			if err := s.app.Delete(r); err != nil {
				log.Error().Err(err).Str("record_id", r.Id).Msg("üî• Failed to delete record from queue after success!")
			}
			metrics.ProcessedTotal.WithLabelValues("success", "batch").Inc()
		}
	}
}

func (s *Service) handleError(record *core.Record, err error, fatal bool) {
	// ... (–æ—Å—Ç–∞–≤–ª—è–µ–º –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π)
	record.Set("error_log", err.Error())

	if fatal {
		log.Error().Str("id", record.GetString("ais_id")).Msg("Moving record to DLQ due to fatal error")
		record.Set("status", "failed")
		s.app.Save(record)
		return
	}

	retryCount := record.GetInt("retry_count")
	if retryCount >= MaxRetries {
		log.Warn().Str("id", record.GetString("ais_id")).Msg("Max retries reached. Moving to DLQ (failed).")
		record.Set("status", "failed")
	} else {
		newCount := retryCount + 1

		// –ò—Å–ø–æ–ª—å–∑—É–µ–º –ª–æ–≥–∏–∫—É backoff: –∏–Ω—Ç–µ—Ä–≤–∞–ª —Ä–∞—Å—Ç–µ—Ç —ç–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–æ
		// 1m, 2m, 4m, 8m, 16m... (–¥–æ MaxRetries)
		interval := BaseRetryInterval * (1 << (newCount - 1))
		if interval > 24*time.Hour { // –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Å–≤–µ—Ä—Ö—É —Å—É—Ç–∫–∞–º–∏
			interval = 24 * time.Hour
		}

		nextTry := time.Now().Add(interval)

		log.Info().Int("attempt", newCount).Time("next_try", nextTry).Str("id", record.GetString("ais_id")).Msg("Scheduling retry")

		record.Set("status", "retry")
		record.Set("retry_count", newCount)
		record.Set("next_attempt", nextTry)
	}
	s.app.Save(record)
}

// RetryFailedTasks –ø–µ—Ä–µ–≤–æ–¥–∏—Ç –≤—Å–µ –∑–∞–ø–∏—Å–∏ –∏–∑ —Å—Ç–∞—Ç—É—Å–∞ failed –≤ pending
func (s *Service) RetryFailedTasks() (int, error) {
	records, err := s.app.FindRecordsByFilter(
		CollectionQueue,
		"status = 'failed'",
		"created",
		0, // 0 = –≤—Å–µ –∑–∞–ø–∏—Å–∏
		0,
		nil,
	)
	if err != nil {
		return 0, err
	}

	count := len(records)
	if count == 0 {
		return 0, nil
	}

	for _, record := range records {
		record.Set("status", "pending")
		record.Set("retry_count", 0)
		record.Set("error_log", "")
		record.Set("next_attempt", nil)
		if err := s.app.Save(record); err != nil {
			log.Error().Err(err).Str("id", record.Id).Msg("Failed to reset failed record")
		}
	}

	// –ë—É–¥–∏–º –¥–∏—Å–ø–µ—Ç—á–µ—Ä
	select {
	case s.notify <- struct{}{}:
	default:
	}

	log.Info().Int("count", count).Msg("üîÑ DLQ: Resetting failed tasks to pending")
	return count, nil
}

func (s *Service) sendBatchToOneC(ctx context.Context, requests []models.AISRequest) error {
	if len(requests) == 0 {
		return nil
	}

	// 1. –¢–µ—Å—Ç–æ–≤–∞—è –ª–æ–≥–∏–∫–∞ –∏–º–∏—Ç–∞—Ü–∏–∏ –æ—à–∏–±–æ–∫ (–¥–ª—è –¥–∞—à–±–æ—Ä–¥–∞)
	for _, req := range requests {
		if strings.Contains(req.ID, "fail") {
			return fmt.Errorf("1C Batch Error: request %s failed (Simulated)", req.ID)
		}
	}

	// 2. –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –∑–∞–ø—Ä–æ—Å—ã –ø–æ –º–µ—Ç–æ–¥–∞–º (1–° –æ–∂–∏–¥–∞–µ—Ç POST –∏ DELETE –Ω–∞ —Ä–∞–∑–Ω—ã—Ö –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∞—Ö)
	batchesByMethod := make(map[string][]models.AISRequest)
	for _, r := range requests {
		batchesByMethod[r.Method] = append(batchesByMethod[r.Method], r)
	}

	// 3. –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∫–∞–∂–¥—É—é –≥—Ä—É–ø–ø—É –æ—Ç–¥–µ–ª—å–Ω—ã–º HTTP –∑–∞–ø—Ä–æ—Å–æ–º
	for method, batch := range batchesByMethod {
		if err := s.doHttpRequest(ctx, method, batch); err != nil {
			return err
		}
	}

	return nil
}

func (s *Service) doHttpRequest(ctx context.Context, method string, batch []models.AISRequest) error {
	// –ë–µ—Ä–µ–º –±—É—Ñ–µ—Ä –∏–∑ –ø—É–ª–∞ –¥–ª—è –º–∞—Ä—à–∞–ª–∏–Ω–≥–∞ –≤—Å–µ–π –ø–∞—á–∫–∏
	buf := s.bufPool.Get().(*bytes.Buffer)
	buf.Reset()
	defer s.bufPool.Put(buf)

	if err := json.NewEncoder(buf).Encode(batch); err != nil {
		return fmt.Errorf("failed to encode batch JSON: %w", err)
	}

	req, err := http.NewRequestWithContext(ctx, method, s.cfg.OneCBaseURL, buf)
	if err != nil {
		return fmt.Errorf("failed to create request: %w", err)
	}

	// –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤
	req.Header.Set("Content-Type", "application/json; charset=utf-8")
	if s.cfg.OneCUser != "" {
		req.SetBasicAuth(s.cfg.OneCUser, s.cfg.OneCPassword)
	}

	res, err := s.client.Do(req)
	if err != nil {
		return fmt.Errorf("1C connection error: %w", err)
	}
	defer res.Body.Close()

	if res.StatusCode < 200 || res.StatusCode >= 300 {
		// –ß–∏—Ç–∞–µ–º —Ç–µ–ª–æ –æ—à–∏–±–∫–∏ –æ—Ç 1–° –¥–ª—è –ª–æ–≥–æ–≤
		errBody, _ := io.ReadAll(res.Body)
		return fmt.Errorf("1C returned error status: %d, body: %s", res.StatusCode, string(errBody))
	}

	return nil
}
