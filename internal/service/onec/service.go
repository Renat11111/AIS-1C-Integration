package onec

import (
	"bytes"
	"context"
	"encoding/json"
	"fmt"
	"net/http"
	"strings"
	"sync"
	"time"

	"ais-1c-proxy/internal/config"
	"ais-1c-proxy/internal/metrics"
	"ais-1c-proxy/internal/models"

	"github.com/cenkalti/backoff/v4"
	"github.com/pocketbase/dbx"
	"github.com/pocketbase/pocketbase"
	"github.com/pocketbase/pocketbase/core"
	"github.com/prometheus/client_golang/prometheus"
	"github.com/rs/zerolog/log"
)

const (
	CollectionQueue   = "integration_queue"
	WorkerCount       = 5
	BatchSize         = 50
	ChannelBuffer     = 100
	MaxRetries        = 10              // –ú–∞–∫—Å–∏–º—É–º –ø–æ–ø—ã—Ç–æ–∫ –ø–µ—Ä–µ–¥ –ø–µ—Ä–µ–º–µ—â–µ–Ω–∏–µ–º –≤ DLQ (failed)
	BaseRetryInterval = 1 * time.Minute // –ù–∞—á–∞–ª—å–Ω—ã–π –∏–Ω—Ç–µ—Ä–≤–∞–ª –ø–æ–≤—Ç–æ—Ä–∞

	// Circuit Breaker Config
	CBFailureThreshold = 5                // –°–∫–æ–ª—å–∫–æ –æ—à–∏–±–æ–∫ –ø–æ–¥—Ä—è–¥ –¥–æ —Ä–∞–∑–º—ã–∫–∞–Ω–∏—è
	CBOpenDuration     = 30 * time.Second // –°–∫–æ–ª—å–∫–æ –∂–¥–∞—Ç—å –ø–µ—Ä–µ–¥ –ø–æ–ø—ã—Ç–∫–æ–π –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è
)

type CBState int

const (
	StateClosed CBState = iota
	StateOpen
	StateHalfOpen
)

type Service struct {
	app     *pocketbase.PocketBase
	cfg     *config.Config
	client  *http.Client
	bufPool sync.Pool
	jobs    chan []*core.Record // –¢–µ–ø–µ—Ä—å –ø–µ—Ä–µ–¥–∞–µ–º –ø–∞—á–∫–∏ –∑–∞–ø–∏—Å–µ–π
	notify  chan struct{}       // –ö–∞–Ω–∞–ª –¥–ª—è –ø—Ä–æ–±—É–∂–¥–µ–Ω–∏—è –¥–∏—Å–ø–µ—Ç—á–µ—Ä–∞
	wg      sync.WaitGroup

	// Circuit Breaker State
	cbState     CBState
	cbFailures  int
	cbLastRetry time.Time
	cbMu        sync.RWMutex
}

func NewService(app *pocketbase.PocketBase, cfg *config.Config) *Service {
	return &Service{
		app:    app,
		cfg:    cfg,
		client: &http.Client{Timeout: cfg.OneCTimeout},
		bufPool: sync.Pool{
			New: func() interface{} {
				return bytes.NewBuffer(make([]byte, 0, 4096)) // 4KB –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–ª—è –æ–¥–Ω–æ–≥–æ –∏–Ω–≤–æ–π—Å–∞
			},
		},
		jobs:    make(chan []*core.Record, ChannelBuffer),
		notify:  make(chan struct{}, 1),
		cbState: StateClosed,
	}
}

func (s *Service) getCBState() CBState {
	// ... (–æ—Å—Ç–∞–≤–ª—è–µ–º –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π)
	s.cbMu.RLock()
	defer s.cbMu.RUnlock()

	if s.cbState == StateOpen {
		if time.Since(s.cbLastRetry) > CBOpenDuration {
			return StateHalfOpen
		}
	}
	return s.cbState
}

func (s *Service) recordCBSuccess() {
	s.cbMu.Lock()
	defer s.cbMu.Unlock()
	s.cbState = StateClosed
	s.cbFailures = 0
	log.Info().Msg("üõ°Ô∏è Circuit Breaker: CLOSED (System restored)")
}

func (s *Service) recordCBFailure() {
	s.cbMu.Lock()
	defer s.cbMu.Unlock()
	s.cbFailures++
	if s.cbFailures >= CBFailureThreshold && s.cbState != StateOpen {
		s.cbState = StateOpen
		s.cbLastRetry = time.Now()
		log.Warn().Int("failures", s.cbFailures).Msg("üõ°Ô∏è Circuit Breaker: OPEN (1C is down, pausing requests)")
	}
}

func (s *Service) EnsureQueueCollection() error {
	// ... (–æ—Å—Ç–∞–≤–ª—è–µ–º –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π)
	col, err := s.app.FindCollectionByNameOrId(CollectionQueue)
	if err != nil {
		log.Info().Msg("Bootstrap: Creating 'integration_queue' collection...")
		col = core.NewBaseCollection(CollectionQueue)
		col.Type = core.CollectionTypeBase
	} else {
		log.Debug().Msg("Bootstrap: Checking 'integration_queue' fields...")
	}

	// –°–ø–∏—Å–æ–∫ –ø–æ–ª–µ–π, –∫–æ—Ç–æ—Ä—ã–µ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –≤ –∫–æ–ª–ª–µ–∫—Ü–∏–∏
	requiredFields := []core.Field{
		&core.TextField{Name: "ais_id", Required: true},
		&core.TextField{Name: "method", Required: true},
		&core.JSONField{Name: "payload", Required: true},
		&core.SelectField{Name: "status", MaxSelect: 1, Values: []string{"pending", "processing", "retry", "failed", "error"}},
		&core.TextField{Name: "error_log"},
		&core.NumberField{Name: "retry_count"},
		&core.DateField{Name: "next_attempt"},
		&core.DateField{Name: "created"},
		&core.DateField{Name: "updated"},
	}

	modified := false
	for _, rf := range requiredFields {
		if col.Fields.GetByName(rf.GetName()) == nil {
			log.Info().Str("field", rf.GetName()).Msg("Adding missing field to collection")
			col.Fields.Add(rf)
			modified = true
		}
	}

	// –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–æ–≤
	indexes := []struct {
		name   string
		unique bool
		cols   string
	}{
		{"idx_status", false, "status"},
		{"idx_ais_id", true, "ais_id"},
		{"idx_next_attempt", false, "next_attempt"},
	}

	for _, idx := range indexes {
		exists := false
		for _, existingIdx := range col.Indexes {
			// –í PocketBase v0.35 –∏–Ω–¥–µ–∫—Å—ã –ø—Ä–æ–≤–µ—Ä—è—é—Ç—Å—è –ø–æ —Å—Ç—Ä–æ–∫–æ–≤–æ–º—É –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—é –∏–ª–∏ –∏–º–µ–Ω–∏
			if existingIdx == idx.name {
				exists = true
				break
			}
		}
		if !exists {
			log.Info().Str("index", idx.name).Msg("Adding missing index to collection")
			col.AddIndex(idx.name, idx.unique, idx.cols, "")
			modified = true
		}
	}

	if modified || col.Id == "" {
		return s.app.Save(col)
	}

	return nil
}

func (s *Service) Push(req models.AISRequest) error {
	collection, err := s.app.FindCollectionByNameOrId(CollectionQueue)
	if err != nil {
		return err
	}
	existing, _ := s.app.FindFirstRecordByFilter(CollectionQueue, "ais_id = {:id}", map[string]interface{}{"id": req.ID})
	if existing != nil {
		log.Warn().Str("id", req.ID).Msg("Duplicate request ID ignored")
		return nil
	}
	record := core.NewRecord(collection)
	record.Set("ais_id", req.ID)
	record.Set("method", req.Method)
	record.Set("payload", req.Data)
	record.Set("status", "pending")

	if err := s.app.Save(record); err != nil {
		return err
	}

	// –£–≤–µ–¥–æ–º–ª—è–µ–º –¥–∏—Å–ø–µ—Ç—á–µ—Ä –æ –Ω–æ–≤–æ–π –∑–∞–ø–∏—Å–∏
	select {
	case s.notify <- struct{}{}:
	default:
		// –ö–∞–Ω–∞–ª –ø–æ–ª–æ–Ω, –¥–∏—Å–ø–µ—Ç—á–µ—Ä –∏ —Ç–∞–∫ –ø—Ä–æ—Å–Ω–µ—Ç—Å—è
	}

	return nil
}

func (s *Service) StartBackgroundWorker(ctx context.Context) {
	for i := 0; i < s.cfg.WorkerCount; i++ {
		s.wg.Add(1)
		go s.worker(ctx, i)
	}
	log.Info().Int("count", s.cfg.WorkerCount).Msg("Started 1C integration workers")

	s.wg.Add(1)
	go s.dispatcher(ctx)
}

// Wait blocks until all background workers are stopped
func (s *Service) Wait() {
	s.wg.Wait()
	log.Info().Msg("All workers stopped gracefully")
}

func (s *Service) dispatcher(ctx context.Context) {
	defer s.wg.Done()
	log.Info().Msg("Started DB Dispatcher (Pure Event-driven)")

	for {
		// 1. –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ç–æ, —á—Ç–æ –≥–æ—Ç–æ–≤–æ –ø—Ä—è–º–æ —Å–µ–π—á–∞—Å
		processed := s.fetchAndDispatch()

		// 2. –ï—Å–ª–∏ –æ–±—Ä–∞–±–æ—Ç–∞–ª–∏ –ø–æ–ª–Ω—É—é –ø–∞—á–∫—É, –≤–æ–∑–º–æ–∂–Ω–æ –µ—Å—Ç—å –µ—â–µ - –∏–¥–µ–º –Ω–∞ –Ω–æ–≤—ã–π –∫—Ä—É–≥ –Ω–µ–º–µ–¥–ª–µ–Ω–Ω–æ
		if processed >= s.cfg.BatchSize {
			continue
		}

		// 3. –í—ã—è—Å–Ω—è–µ–º, –∫–æ–≥–¥–∞ –ø—Ä–æ—Å–Ω—É—Ç—å—Å—è –≤ —Å–ª–µ–¥—É—é—â–∏–π —Ä–∞–∑
		// –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é —Å–ø–∏–º 1 –º–∏–Ω—É—Ç—É (–∫–∞–∫ watchdog), –µ—Å–ª–∏ –∑–∞–¥–∞—á –Ω–µ—Ç
		waitDuration := 1 * time.Minute

		// –ò—â–µ–º –≤—Ä–µ–º—è –±–ª–∏–∂–∞–π—à–µ–≥–æ –ø–æ–≤—Ç–æ—Ä–∞
		var nextAttemptStr string
		err := s.app.DB().Select("MIN(next_attempt)").
			From(CollectionQueue).
			Where(dbx.NewExp("status = 'retry'")).
			Row(&nextAttemptStr)

		if err == nil && nextAttemptStr != "" {
			// PocketBase –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –≤—Ä–µ–º—è –≤ —Ñ–æ—Ä–º–∞—Ç–µ UTC
			nextTime, parseErr := time.Parse("2006-01-02 15:04:05.000Z", nextAttemptStr)
			if parseErr == nil {
				waitDuration = time.Until(nextTime)
				if waitDuration < 0 {
					waitDuration = 0 // –£–∂–µ –ø–æ—Ä–∞ –±—ã–ª–æ –∑–∞–ø—É—Å—Ç–∏—Ç—å
				}
				// –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –æ–∂–∏–¥–∞–Ω–∏–µ 1 –º–∏–Ω—É—Ç–æ–π –Ω–∞ —Å–ª—É—á–∞–π –ø—Ä–∞–≤–æ–∫ –≤ Admin UI
				if waitDuration > 1*time.Minute {
					waitDuration = 1 * time.Minute
				}
			}
		}

		timer := time.NewTimer(waitDuration)

		select {
		case <-ctx.Done():
			timer.Stop()
			log.Info().Msg("Dispatcher stopping...")
			return
		case <-s.notify:
			timer.Stop()
			// –ü—Ä–æ—Å–Ω—É–ª–∏—Å—å –ø–æ —Å–∏–≥–Ω–∞–ª—É –æ –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
		case <-timer.C:
			// –ù–∞—Å—Ç—É–ø–∏–ª–æ –≤—Ä–µ–º—è –∑–∞–ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –ø–æ–≤—Ç–æ—Ä–∞
		}
	}
}
func (s *Service) fetchAndDispatch() int {
	// –°—á–∏—Ç–∞–µ–º –≥–ª—É–±–∏–Ω—É –æ—á–µ—Ä–µ–¥–∏ (–æ–∂–∏–¥–∞—é—â–∏–µ + –ø–æ–≤—Ç–æ—Ä—ã)
	totalPending, _ := s.app.CountRecords(CollectionQueue, dbx.NewExp("status = 'pending' OR status = 'retry'"))
	metrics.QueueDepth.Set(float64(totalPending))

	// –§–∏–ª—å—Ç—Ä: –ª–∏–±–æ –Ω–æ–≤—ã–µ, –ª–∏–±–æ —Ç–µ, –∫–æ–º—É –ø–æ—Ä–∞ —Å–¥–µ–ª–∞—Ç—å –ø–æ–≤—Ç–æ—Ä
	filter := "status = 'pending' || (status = 'retry' && next_attempt <= @now)"

	records, err := s.app.FindRecordsByFilter(
		CollectionQueue,
		filter,
		"created",
		s.cfg.BatchSize,
		0,
		nil,
	)
	if err != nil {
		log.Error().Err(err).Msg("Dispatcher failed to fetch records")
		return 0
	}

	count := len(records)
	if count == 0 {
		return 0
	}

	log.Debug().Int("count", count).Msg("Dispatcher found tasks")

	// –ë–ª–æ–∫–∏—Ä—É–µ–º –≤—Å—é –ø–∞—á–∫—É —Å—Ä–∞–∑—É
	for _, record := range records {
		record.Set("status", "processing")
		if err := s.app.Save(record); err != nil {
			log.Error().Err(err).Str("id", record.Id).Msg("Failed to lock record")
			continue
		}
	}

	// –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤—Å—é –ø–∞—á–∫—É –≤ –∫–∞–Ω–∞–ª –∫–∞–∫ –û–î–ù–£ –∑–∞–¥–∞—á—É –¥–ª—è –≤–æ—Ä–∫–µ—Ä–∞
	s.jobs <- records

	return count
}

func (s *Service) worker(ctx context.Context, id int) {
	defer s.wg.Done()
	for {
		select {
		case <-ctx.Done():
			log.Debug().Int("worker_id", id).Msg("Worker stopping...")
			return
		case records := <-s.jobs:
			s.processBatch(ctx, id, records)
		}
	}
}

func (s *Service) processBatch(ctx context.Context, workerID int, records []*core.Record) {
	if len(records) == 0 {
		return
	}

	timer := prometheus.NewTimer(metrics.WorkerDuration)
	defer timer.ObserveDuration()

	// 1. –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ Circuit Breaker
	state := s.getCBState()
	if state == StateOpen {
		log.Debug().Int("batch_size", len(records)).Msg("üõ°Ô∏è Circuit Breaker is OPEN. Skipping batch.")
		for _, r := range records {
			s.handleError(r, fmt.Errorf("circuit breaker is open"), false)
		}
		return
	}

	// 2. –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ (–∏—Å–ø–æ–ª—å–∑—É–µ–º –ø—É–ª –±—É—Ñ–µ—Ä–æ–≤)
	buf := s.bufPool.Get().(*bytes.Buffer)
	buf.Reset()
	defer s.bufPool.Put(buf)

	batchRequests := make([]models.AISRequest, 0, len(records))
	for _, record := range records {
		var payloadData models.AISDocument

		// –û—á–∏—â–∞–µ–º –±—É—Ñ–µ—Ä –¥–ª—è –∫–∞–∂–¥–æ–π –∑–∞–ø–∏—Å–∏ –≤ –±–∞—Ç—á–µ
		buf.Reset()

		// –ö–æ–¥–∏—Ä—É–µ–º payload –∏–∑ –∑–∞–ø–∏—Å–∏ –≤ –±—É—Ñ–µ—Ä
		if err := json.NewEncoder(buf).Encode(record.Get("payload")); err != nil {
			log.Error().Err(err).Str("record_id", record.Id).Msg("Failed to encode payload in batch")
			s.handleError(record, err, true)
			continue
		}

		// –î–µ–∫–æ–¥–∏—Ä—É–µ–º –∏–∑ –±—É—Ñ–µ—Ä–∞ –≤ —Å—Ç—Ä—É–∫—Ç—É—Ä—É
		if err := json.NewDecoder(buf).Decode(&payloadData); err != nil {
			log.Error().Err(err).Str("record_id", record.Id).Msg("Failed to decode payload in batch")
			s.handleError(record, err, true)
			continue
		}

		batchRequests = append(batchRequests, models.AISRequest{
			ID:     record.GetString("ais_id"),
			Method: record.GetString("method"),
			Data:   payloadData,
		})
	}

	if len(batchRequests) == 0 {
		return
	}

	// –î–ª—è –ª–æ–≥–æ–≤ –±–µ—Ä–µ–º SaleId –ø–µ—Ä–≤–æ–π –∑–∞–ø–∏—Å–∏
	firstSaleID := fmt.Sprintf("%v", batchRequests[0].Data.SaleId)
	log.Info().Int("worker", workerID).Int("batch_size", len(batchRequests)).Str("first_sale_id", firstSaleID).Msg("üöÄ Processing batch")

	// 3. –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –ü–ê–ö–ï–¢ –≤ 1–°
	err := s.sendBatchToOneC(ctx, batchRequests)

	if err != nil {
		log.Error().Err(err).Int("batch_size", len(batchRequests)).Msg("‚ùå Batch sync failed")
		s.recordCBFailure()
		for _, r := range records {
			s.handleError(r, err, false)
			metrics.ProcessedTotal.WithLabelValues("error", "batch").Inc()
		}
	} else {
		log.Info().Int("batch_size", len(batchRequests)).Msg("‚úÖ Batch sync success")
		s.recordCBSuccess()
		for _, r := range records {
			s.app.Delete(r)
			metrics.ProcessedTotal.WithLabelValues("success", "batch").Inc()
		}
	}
}

func (s *Service) handleError(record *core.Record, err error, fatal bool) {
	// ... (–æ—Å—Ç–∞–≤–ª—è–µ–º –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π)
	record.Set("error_log", err.Error())

	if fatal {
		log.Error().Str("id", record.GetString("ais_id")).Msg("Moving record to DLQ due to fatal error")
		record.Set("status", "failed")
		s.app.Save(record)
		return
	}

	retryCount := record.GetInt("retry_count")
	if retryCount >= MaxRetries {
		log.Warn().Str("id", record.GetString("ais_id")).Msg("Max retries reached. Moving to DLQ (failed).")
		record.Set("status", "failed")
	} else {
		newCount := retryCount + 1

		// –ò—Å–ø–æ–ª—å–∑—É–µ–º –ª–æ–≥–∏–∫—É backoff: –∏–Ω—Ç–µ—Ä–≤–∞–ª —Ä–∞—Å—Ç–µ—Ç —ç–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–æ
		// 1m, 2m, 4m, 8m, 16m... (–¥–æ MaxRetries)
		interval := BaseRetryInterval * (1 << (newCount - 1))
		if interval > 24*time.Hour { // –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Å–≤–µ—Ä—Ö—É —Å—É—Ç–∫–∞–º–∏
			interval = 24 * time.Hour
		}

		nextTry := time.Now().Add(interval)

		log.Info().Int("attempt", newCount).Time("next_try", nextTry).Str("id", record.GetString("ais_id")).Msg("Scheduling retry")

		record.Set("status", "retry")
		record.Set("retry_count", newCount)
		record.Set("next_attempt", nextTry)
	}
	s.app.Save(record)
}

// RetryFailedTasks –ø–µ—Ä–µ–≤–æ–¥–∏—Ç –≤—Å–µ –∑–∞–ø–∏—Å–∏ –∏–∑ —Å—Ç–∞—Ç—É—Å–∞ failed –≤ pending
func (s *Service) RetryFailedTasks() (int, error) {
	records, err := s.app.FindRecordsByFilter(
		CollectionQueue,
		"status = 'failed'",
		"created",
		0, // 0 = –≤—Å–µ –∑–∞–ø–∏—Å–∏
		0,
		nil,
	)
	if err != nil {
		return 0, err
	}

	count := len(records)
	if count == 0 {
		return 0, nil
	}

	for _, record := range records {
		record.Set("status", "pending")
		record.Set("retry_count", 0)
		record.Set("error_log", "")
		record.Set("next_attempt", nil)
		if err := s.app.Save(record); err != nil {
			log.Error().Err(err).Str("id", record.Id).Msg("Failed to reset failed record")
		}
	}

	// –ë—É–¥–∏–º –¥–∏—Å–ø–µ—Ç—á–µ—Ä
	select {
	case s.notify <- struct{}{}:
	default:
	}

	log.Info().Int("count", count).Msg("üîÑ DLQ: Resetting failed tasks to pending")
	return count, nil
}

func (s *Service) sendBatchToOneC(ctx context.Context, requests []models.AISRequest) error {
	// –í –±—É–¥—É—â–µ–º –∑–¥–µ—Å—å –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è backoff –¥–ª—è –ø–æ–≤—Ç–æ—Ä–Ω—ã—Ö –ø–æ–ø—ã—Ç–æ–∫ –Ω–∞ —É—Ä–æ–≤–Ω–µ HTTP
	_ = backoff.NewExponentialBackOff()

	// –ò–º–∏—Ç–∏—Ä—É–µ–º —Å–µ—Ç–µ–≤—É—é –∑–∞–¥–µ—Ä–∂–∫—É –Ω–∞ –æ–±—Ä–∞–±–æ—Ç–∫—É –ø–∞–∫–µ—Ç–∞
	time.Sleep(500 * time.Millisecond)

	// –¢–µ—Å—Ç–æ–≤–∞—è –ª–æ–≥–∏–∫–∞: –µ—Å–ª–∏ —Ö–æ—Ç—è –±—ã –≤ –æ–¥–Ω–æ–º ID –µ—Å—Ç—å "fail", –≤–µ—Å—å –±–∞—Ç—á –ø–∞–¥–∞–µ—Ç
	for _, req := range requests {
		if strings.Contains(req.ID, "fail") {
			return fmt.Errorf("1C Batch Error: request %s failed (Simulated)", req.ID)
		}
	}

	return nil
}
